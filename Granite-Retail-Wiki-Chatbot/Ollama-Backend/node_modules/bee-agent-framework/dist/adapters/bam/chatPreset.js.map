{"version":3,"sources":["../../../src/adapters/bam/chatPreset.ts"],"names":["BAMChatLLMPreset","template","parameters","messagesToPrompt","LLMChatTemplates","get","base","decoding_method","include_stop_sequence","max_new_tokens","repetition_penalty","stop_sequences","stop_sequence","chat"],"mappings":";;;;AAyBO,MAAMA,gBAAmB,GAAA;AAC9B,EAAA,mCAAA,kBAAqC,MAAA,CAAA,MAAA;AACnC,IAAA,MAAM,EAAEC,QAAUC,EAAAA,UAAAA,EAAYC,kBAAqBC,GAAAA,gBAAAA,CAAiBC,IAAI,UAAA,CAAA;AAExE,IAAO,OAAA;MACLC,IAAM,EAAA;QACJJ,UAAY,EAAA;UACVK,eAAiB,EAAA,QAAA;UACjBC,qBAAuB,EAAA,KAAA;UACvBC,cAAgB,EAAA,IAAA;UAChBC,kBAAoB,EAAA,CAAA;UACpBC,cAAgB,EAAA;eAAIT,UAAWU,CAAAA;;AACjC;AACF,OAAA;MACAC,IAAM,EAAA;AACJV,QAAAA,gBAAAA,EAAkBA,iBAAiBF,QAAAA;AACrC;AACF,KAAA;GAhBmC,EAAA,mCAAA,CAAA;AAkBrC,EAAA,mCAAA,kBAAqC,MAAA,CAAA,MAAA;AACnC,IAAA,MAAM,EAAEA,QAAUC,EAAAA,UAAAA,EAAYC,kBAAqBC,GAAAA,gBAAAA,CAAiBC,IAAI,UAAA,CAAA;AAExE,IAAO,OAAA;MACLC,IAAM,EAAA;QACJJ,UAAY,EAAA;UACVK,eAAiB,EAAA,QAAA;UACjBC,qBAAuB,EAAA,KAAA;UACvBC,cAAgB,EAAA,IAAA;UAChBC,kBAAoB,EAAA,CAAA;UACpBC,cAAgB,EAAA;eAAIT,UAAWU,CAAAA;;AACjC;AACF,OAAA;MACAC,IAAM,EAAA;AACJV,QAAAA,gBAAAA,EAAkBA,iBAAiBF,QAAAA;AACrC;AACF,KAAA;GAhBmC,EAAA,mCAAA,CAAA;EAkBrC,gCAAA,GAAA;AACE,IAAOD,OAAAA,gBAAAA,CAAiB,iCAAA,CAAkC,EAAA;AAC5D,GAAA;AACA,EAAA,iCAAA,kBAAmC,MAAA,CAAA,MAAA;AACjC,IAAA,MAAM,EAAEC,QAAUC,EAAAA,UAAAA,EAAYC,kBAAqBC,GAAAA,gBAAAA,CAAiBC,IAAI,QAAA,CAAA;AAExE,IAAO,OAAA;MACLC,IAAM,EAAA;QACJJ,UAAY,EAAA;UACVK,eAAiB,EAAA,QAAA;UACjBE,cAAgB,EAAA,IAAA;UAChBD,qBAAuB,EAAA,KAAA;UACvBG,cAAgB,EAAA;eAAIT,UAAWU,CAAAA;;AACjC;AACF,OAAA;MACAC,IAAM,EAAA;AACJV,QAAAA,gBAAAA,EAAkBA,iBAAiBF,QAAAA;AACrC;AACF,KAAA;GAfiC,EAAA,iCAAA;AAiBrC","file":"chatPreset.js","sourcesContent":["/**\n * Copyright 2024 IBM Corp.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BAMChatLLMInputConfig } from \"@/adapters/bam/chat.js\";\nimport { BAMLLMInput } from \"@/adapters/bam/llm.js\";\nimport { LLMChatTemplates } from \"@/adapters/shared/llmChatTemplates.js\";\n\ninterface BAMChatLLMPreset {\n  chat: BAMChatLLMInputConfig;\n  base: Omit<BAMLLMInput, \"client\" | \"modelId\">;\n}\n\nexport const BAMChatLLMPreset = {\n  \"meta-llama/llama-3-3-70b-instruct\": (): BAMChatLLMPreset => {\n    const { template, parameters, messagesToPrompt } = LLMChatTemplates.get(\"llama3.3\");\n\n    return {\n      base: {\n        parameters: {\n          decoding_method: \"greedy\",\n          include_stop_sequence: false,\n          max_new_tokens: 2048,\n          repetition_penalty: 1,\n          stop_sequences: [...parameters.stop_sequence],\n        },\n      },\n      chat: {\n        messagesToPrompt: messagesToPrompt(template),\n      },\n    };\n  },\n  \"meta-llama/llama-3-1-70b-instruct\": (): BAMChatLLMPreset => {\n    const { template, parameters, messagesToPrompt } = LLMChatTemplates.get(\"llama3.1\");\n\n    return {\n      base: {\n        parameters: {\n          decoding_method: \"greedy\",\n          include_stop_sequence: false,\n          max_new_tokens: 2048,\n          repetition_penalty: 1,\n          stop_sequences: [...parameters.stop_sequence],\n        },\n      },\n      chat: {\n        messagesToPrompt: messagesToPrompt(template),\n      },\n    };\n  },\n  \"meta-llama/llama-3-8b-instruct\"() {\n    return BAMChatLLMPreset[\"meta-llama/llama-3-70b-instruct\"]();\n  },\n  \"meta-llama/llama-3-70b-instruct\": (): BAMChatLLMPreset => {\n    const { template, parameters, messagesToPrompt } = LLMChatTemplates.get(\"llama3\");\n\n    return {\n      base: {\n        parameters: {\n          decoding_method: \"greedy\",\n          max_new_tokens: 1500,\n          include_stop_sequence: false,\n          stop_sequences: [...parameters.stop_sequence],\n        },\n      },\n      chat: {\n        messagesToPrompt: messagesToPrompt(template),\n      },\n    };\n  },\n} as const;\n\nexport type BAMChatLLMPresetModel = keyof typeof BAMChatLLMPreset;\n"]}