{"version":3,"sources":["../../../src/adapters/bam/chat.ts"],"names":["BAMChatLLMOutput","ChatLLMOutput","raw","constructor","rawOutput","finalResult","messages","text","getTextContent","BaseMessage","of","role","meta","merge","other","Cache","getInstance","clear","message","toString","createSnapshot","shallowCopy","loadSnapshot","snapshot","Object","assign","BAMChatLLM","ChatLLM","emitter","Emitter","root","child","namespace","creator","llm","config","cache","modelId","executionOptions","register","embed","input","options","inputs","map","messagesToPrompt","tokenize","prompt","_generate","run","rawResponse","_stream","response","transformAsyncIterable","output","fromPreset","overrides","presetFactory","BAMChatLLMPreset","LLMError","preset","parameters","base","isFunction","isObjectType","chat","BAMLLM","client","Client"],"mappings":";;;;;;;;;;;;;;AAcC,SAAA,YAAA,CAAA,UAAA,EAAA,MAAA,EAAA,GAAA,EAAA,IAAA,EAAA;;;;;;AAAA,MAAA,CAAA,YAAA,EAAA,cAAA,CAAA;;;;;AA2BM,MAAMA,yBAAyBC,aAAAA,CAAAA;EAzCtC;;;AA0CkBC,EAAAA,GAAAA;AAEhBC,EAAAA,WAAAA,CAAYC,SAAyB,EAAA;AACnC,IAAK,KAAA,EAAA;AACL,IAAA,IAAA,CAAKF,GAAME,GAAAA,SAAAA;AACb;AAEA,EAAA,IAAIC,WAAc,GAAA;AAChB,IAAA,OAAO,KAAKH,GAAIG,CAAAA,WAAAA;AAClB;AAEA,EAAA,IACIC,QAA0B,GAAA;AAC5B,IAAMC,MAAAA,IAAAA,GAAO,IAAKL,CAAAA,GAAAA,CAAIM,cAAc,EAAA;AACpC,IAAO,OAAA;AACLC,MAAAA,WAAAA,CAAYC,EAAG,CAAA;QACbC,IAAM,EAAA,WAAA;AACNJ,QAAAA,IAAAA;AACAK,QAAAA,IAAAA,EAAM,KAAKV,GAAIU,CAAAA;OACjB;;AAEJ;AAEAC,EAAAA,KAAAA,CAAMC,KAA+B,EAAA;AACnCC,IAAAA,KAAAA,CAAMC,WAAY,CAAA,IAAA,EAAM,UAAA,CAAA,CAAYC,KAAK,EAAA;AACzC,IAAKf,IAAAA,CAAAA,GAAAA,CAAIW,KAAMC,CAAAA,KAAAA,CAAMZ,GAAG,CAAA;AAC1B;EAEAM,cAAyB,GAAA;AACvB,IAAM,MAAA,CAACU,OAAAA,CAAAA,GAAW,IAAKZ,CAAAA,QAAAA;AACvB,IAAA,OAAOY,OAAQX,CAAAA,IAAAA;AACjB;EAEAY,QAAmB,GAAA;AACjB,IAAA,OAAO,KAAKX,cAAc,EAAA;AAC5B;EAEAY,cAAiB,GAAA;AACf,IAAO,OAAA;MACLlB,GAAKmB,EAAAA,WAAAA,CAAY,KAAKnB,GAAG;AAC3B,KAAA;AACF;AAEAoB,EAAAA,YAAAA,CAAaC,QAAkD,EAAA;AAC7DC,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMF,QAAAA,CAAAA;AACtB;AACF;;;;;;AAcO,MAAMG,mBAAmBC,OAAAA,CAAAA;EAtGhC;;;EAuGkBC,OAAUC,GAAAA,OAAAA,CAAQC,KAAKC,KAAwB,CAAA;IAC7DC,SAAW,EAAA;AAAC,MAAA,KAAA;AAAO,MAAA;;IACnBC,OAAS,EAAA;GACX,CAAA;AAEgBC,EAAAA,GAAAA;AACGC,EAAAA,MAAAA;AAEnBhC,EAAAA,WAAAA,CAAY,EAAE+B,GAAAA,EAAKC,MAAQC,EAAAA,KAAAA,EAA0B,EAAA;AACnD,IAAA,KAAA,CAAMF,GAAIG,CAAAA,OAAAA,EAASH,GAAII,CAAAA,gBAAAA,EAAkBF,KAAAA,CAAAA;AACzC,IAAA,IAAA,CAAKF,GAAMA,GAAAA,GAAAA;AACX,IAAA,IAAA,CAAKC,MAASA,GAAAA,MAAAA;AAChB;EAEA;AACE,IAAA,IAAA,CAAKI,QAAQ,EAAA;AACf;AAEA,EAAA,MAAM3B,IAAO,GAAA;AACX,IAAO,OAAA,IAAA,CAAKsB,IAAItB,IAAI,EAAA;AACtB;EAEA,MAAM4B,KAAAA,CAAMC,OAAwBC,OAAsD,EAAA;AACxF,IAAMC,MAAAA,MAAAA,GAASF,MAAMG,GAAI,CAAA,CAACtC,aAAa,IAAKuC,CAAAA,gBAAAA,CAAiBvC,QAAAA,CAAAA,CAAAA;AAC7D,IAAA,OAAO,IAAK4B,CAAAA,GAAAA,CAAIM,KAAMG,CAAAA,MAAAA,EAAQD,OAAAA,CAAAA;AAChC;EAEAtB,cAAiB,GAAA;AACf,IAAO,OAAA;AACL,MAAA,GAAG,MAAMA,cAAAA,EAAAA;AACTiB,MAAAA,OAAAA,EAAS,IAAKA,CAAAA,OAAAA;MACdC,gBAAkBjB,EAAAA,WAAAA,CAAY,KAAKiB,gBAAgB,CAAA;AACnDJ,MAAAA,GAAAA,EAAK,IAAKA,CAAAA,GAAAA;MACVC,MAAQd,EAAAA,WAAAA,CAAY,KAAKc,MAAM;AACjC,KAAA;AACF;AAEA,EAAA,MAAMW,SAASxC,QAAyB,EAAA;AACtC,IAAMyC,MAAAA,MAAAA,GAAS,IAAKF,CAAAA,gBAAAA,CAAiBvC,QAAAA,CAAAA;AACrC,IAAO,OAAA,IAAA,CAAK4B,GAAIY,CAAAA,QAAAA,CAASC,MAAAA,CAAAA;AAC3B;EAEA,MAAgBC,SAAAA,CACd1C,QACAoC,EAAAA,OAAAA,EACAO,GAC2B,EAAA;AAC3B,IAAMF,MAAAA,MAAAA,GAAS,IAAKF,CAAAA,gBAAAA,CAAiBvC,QAAAA,CAAAA;AAErC,IAAA,MAAM4C,cAAc,MAAM,IAAA,CAAKhB,IAAIc,SAAUD,CAAAA,MAAAA,EAAQL,SAASO,GAAAA,CAAAA;AAC9D,IAAO,OAAA,IAAIjD,iBAAiBkD,WAAAA,CAAAA;AAC9B;EAEA,OAAiBC,OAAAA,CACf7C,QACAoC,EAAAA,OAAAA,EACAO,GACqC,EAAA;AACrC,IAAMF,MAAAA,MAAAA,GAAS,IAAKF,CAAAA,gBAAAA,CAAiBvC,QAAAA,CAAAA;AAErC,IAAA,MAAM8C,WAAW,IAAKlB,CAAAA,GAAAA,CAAIiB,OAAQJ,CAAAA,MAAAA,EAAQL,SAASO,GAAAA,CAAAA;AACnD,IAAO,OAAA,OAAOI,uBAAuBD,QAAU,EAAA,CAACE,WAAW,IAAItD,gBAAAA,CAAiBsD,MAAAA,CAAAA,CAAAA;AAClF;AAEAT,EAAAA,gBAAAA,CAAiBvC,QAAyB,EAAA;AACxC,IAAO,OAAA,IAAA,CAAK6B,MAAOU,CAAAA,gBAAAA,CAAiBvC,QAAAA,CAAAA;AACtC;EAEA,OAAOiD,UAAAA,CACLlB,SACAmB,SAIA,EAAA;AACA,IAAMC,MAAAA,aAAAA,GAAgBC,iBAAiBrB,OAAAA,CAAAA;AACvC,IAAA,IAAI,CAACoB,aAAe,EAAA;AAClB,MAAA,MAAM,IAAIE,QAAAA,CAAS,CAAUtB,OAAAA,EAAAA,OAAAA,CAAoC,2BAAA,CAAA,CAAA;AACnE;AAEA,IAAA,MAAMuB,SAASH,aAAAA,EAAAA;AACf,IAAA,IAAII,UAAaD,GAAAA,MAAAA,CAAOE,IAAKD,CAAAA,UAAAA,IAAc,EAAC;AAC5C,IAAIE,IAAAA,UAAAA,CAAWP,SAAWK,EAAAA,UAAAA,CAAa,EAAA;AACrCA,MAAaL,UAAAA,GAAAA,SAAAA,EAAWK,WAAWA,UAAAA,CAAAA;KAC1BG,MAAAA,IAAAA,YAAAA,CAAaR,SAAWK,EAAAA,UAAAA,CAAa,EAAA;AAC9CA,MAAAA,UAAAA,GAAaL,SAAWK,EAAAA,UAAAA;AAC1B;AAEA,IAAA,OAAO,IAAInC,UAAW,CAAA;AACpBS,MAAAA,MAAAA,EAAQyB,MAAOK,CAAAA,IAAAA;AACf/B,MAAAA,GAAAA,EAAK,IAAIgC,MAAO,CAAA;AACd,QAAA,GAAGN,MAAOE,CAAAA,IAAAA;QACV,GAAGN,SAAAA;AACHK,QAAAA,UAAAA;QACAM,MAAQX,EAAAA,SAAAA,EAAWW,MAAU,IAAA,IAAIC,MAAAA,EAAAA;AACjC/B,QAAAA;OACF;KACF,CAAA;AACF;AACF","file":"chat.js","sourcesContent":["/**\n * Copyright 2024 IBM Corp.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AsyncStream,\n  EmbeddingOptions,\n  EmbeddingOutput,\n  LLMCache,\n  LLMError,\n  StreamGenerateOptions,\n} from \"@/llms/base.js\";\nimport { isFunction, isObjectType } from \"remeda\";\nimport {\n  BAMLLM,\n  BAMLLMGenerateOptions,\n  BAMLLMParameters,\n  BAMLLMOutput,\n} from \"@/adapters/bam/llm.js\";\nimport { ChatLLM, ChatLLMGenerateEvents, ChatLLMOutput } from \"@/llms/chat.js\";\nimport { BaseMessage } from \"@/llms/primitives/message.js\";\nimport { Cache } from \"@/cache/decoratorCache.js\";\nimport { BAMChatLLMPreset, BAMChatLLMPresetModel } from \"@/adapters/bam/chatPreset.js\";\nimport { Client } from \"@ibm-generative-ai/node-sdk\";\nimport { transformAsyncIterable } from \"@/internals/helpers/stream.js\";\nimport { shallowCopy } from \"@/serializer/utils.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport { GetRunContext } from \"@/context.js\";\n\nexport class BAMChatLLMOutput extends ChatLLMOutput {\n  public readonly raw: BAMLLMOutput;\n\n  constructor(rawOutput: BAMLLMOutput) {\n    super();\n    this.raw = rawOutput;\n  }\n\n  get finalResult() {\n    return this.raw.finalResult;\n  }\n\n  @Cache()\n  get messages(): BaseMessage[] {\n    const text = this.raw.getTextContent();\n    return [\n      BaseMessage.of({\n        role: \"assistant\",\n        text,\n        meta: this.raw.meta,\n      }),\n    ];\n  }\n\n  merge(other: BAMChatLLMOutput): void {\n    Cache.getInstance(this, \"messages\").clear();\n    this.raw.merge(other.raw);\n  }\n\n  getTextContent(): string {\n    const [message] = this.messages;\n    return message.text;\n  }\n\n  toString(): string {\n    return this.getTextContent();\n  }\n\n  createSnapshot() {\n    return {\n      raw: shallowCopy(this.raw),\n    };\n  }\n\n  loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>) {\n    Object.assign(this, snapshot);\n  }\n}\n\nexport interface BAMChatLLMInputConfig {\n  messagesToPrompt: (messages: BaseMessage[]) => string;\n}\n\nexport interface BAMChatLLMInput {\n  llm: BAMLLM;\n  config: BAMChatLLMInputConfig;\n  cache?: LLMCache<BAMChatLLMOutput>;\n}\n\nexport type BAMChatLLMEvents = ChatLLMGenerateEvents<BAMChatLLMOutput>;\n\nexport class BAMChatLLM extends ChatLLM<BAMChatLLMOutput> {\n  public readonly emitter = Emitter.root.child<BAMChatLLMEvents>({\n    namespace: [\"bam\", \"chat_llm\"],\n    creator: this,\n  });\n\n  public readonly llm: BAMLLM;\n  protected readonly config: BAMChatLLMInputConfig;\n\n  constructor({ llm, config, cache }: BAMChatLLMInput) {\n    super(llm.modelId, llm.executionOptions, cache);\n    this.llm = llm;\n    this.config = config;\n  }\n\n  static {\n    this.register();\n  }\n\n  async meta() {\n    return this.llm.meta();\n  }\n\n  async embed(input: BaseMessage[][], options?: EmbeddingOptions): Promise<EmbeddingOutput> {\n    const inputs = input.map((messages) => this.messagesToPrompt(messages));\n    return this.llm.embed(inputs, options);\n  }\n\n  createSnapshot() {\n    return {\n      ...super.createSnapshot(),\n      modelId: this.modelId,\n      executionOptions: shallowCopy(this.executionOptions),\n      llm: this.llm,\n      config: shallowCopy(this.config),\n    };\n  }\n\n  async tokenize(messages: BaseMessage[]) {\n    const prompt = this.messagesToPrompt(messages);\n    return this.llm.tokenize(prompt);\n  }\n\n  protected async _generate(\n    messages: BaseMessage[],\n    options: BAMLLMGenerateOptions | undefined,\n    run: GetRunContext<typeof this>,\n  ): Promise<BAMChatLLMOutput> {\n    const prompt = this.messagesToPrompt(messages);\n    // @ts-expect-error protected property\n    const rawResponse = await this.llm._generate(prompt, options, run);\n    return new BAMChatLLMOutput(rawResponse);\n  }\n\n  protected async *_stream(\n    messages: BaseMessage[],\n    options: StreamGenerateOptions | undefined,\n    run: GetRunContext<typeof this>,\n  ): AsyncStream<BAMChatLLMOutput, void> {\n    const prompt = this.messagesToPrompt(messages);\n    // @ts-expect-error protected property\n    const response = this.llm._stream(prompt, options, run);\n    return yield* transformAsyncIterable(response, (output) => new BAMChatLLMOutput(output));\n  }\n\n  messagesToPrompt(messages: BaseMessage[]) {\n    return this.config.messagesToPrompt(messages);\n  }\n\n  static fromPreset(\n    modelId: BAMChatLLMPresetModel,\n    overrides?: {\n      client?: Client;\n      parameters?: BAMLLMParameters | ((value: BAMLLMParameters) => BAMLLMParameters);\n    },\n  ) {\n    const presetFactory = BAMChatLLMPreset[modelId];\n    if (!presetFactory) {\n      throw new LLMError(`Model \"${modelId}\" does not exist in preset.`);\n    }\n\n    const preset = presetFactory();\n    let parameters = preset.base.parameters ?? {};\n    if (isFunction(overrides?.parameters)) {\n      parameters = overrides?.parameters(parameters);\n    } else if (isObjectType(overrides?.parameters)) {\n      parameters = overrides?.parameters;\n    }\n\n    return new BAMChatLLM({\n      config: preset.chat,\n      llm: new BAMLLM({\n        ...preset.base,\n        ...overrides,\n        parameters,\n        client: overrides?.client ?? new Client(),\n        modelId,\n      }),\n    });\n  }\n}\n"]}