'use strict';

var base_cjs = require('../../llms/base.cjs');
var remeda = require('remeda');
var llm_cjs = require('./llm.cjs');
var chat_cjs = require('../../llms/chat.cjs');
var message_cjs = require('../../llms/primitives/message.cjs');
var decoratorCache_cjs = require('../../cache/decoratorCache.cjs');
var chatPreset_cjs = require('./chatPreset.cjs');
var nodeSdk = require('@ibm-generative-ai/node-sdk');
var stream_cjs = require('../../internals/helpers/stream.cjs');
var utils_cjs = require('../../serializer/utils.cjs');
var emitter_cjs = require('../../emitter/emitter.cjs');

var __defProp = Object.defineProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
function _ts_decorate(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
}
__name(_ts_decorate, "_ts_decorate");
function _ts_metadata(k, v) {
  if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(k, v);
}
__name(_ts_metadata, "_ts_metadata");
class BAMChatLLMOutput extends chat_cjs.ChatLLMOutput {
  static {
    __name(this, "BAMChatLLMOutput");
  }
  raw;
  constructor(rawOutput) {
    super();
    this.raw = rawOutput;
  }
  get finalResult() {
    return this.raw.finalResult;
  }
  get messages() {
    const text = this.raw.getTextContent();
    return [
      message_cjs.BaseMessage.of({
        role: "assistant",
        text,
        meta: this.raw.meta
      })
    ];
  }
  merge(other) {
    decoratorCache_cjs.Cache.getInstance(this, "messages").clear();
    this.raw.merge(other.raw);
  }
  getTextContent() {
    const [message] = this.messages;
    return message.text;
  }
  toString() {
    return this.getTextContent();
  }
  createSnapshot() {
    return {
      raw: utils_cjs.shallowCopy(this.raw)
    };
  }
  loadSnapshot(snapshot) {
    Object.assign(this, snapshot);
  }
}
_ts_decorate([
  decoratorCache_cjs.Cache(),
  _ts_metadata("design:type", Array),
  _ts_metadata("design:paramtypes", [])
], BAMChatLLMOutput.prototype, "messages", null);
class BAMChatLLM extends chat_cjs.ChatLLM {
  static {
    __name(this, "BAMChatLLM");
  }
  emitter = emitter_cjs.Emitter.root.child({
    namespace: [
      "bam",
      "chat_llm"
    ],
    creator: this
  });
  llm;
  config;
  constructor({ llm, config, cache }) {
    super(llm.modelId, llm.executionOptions, cache);
    this.llm = llm;
    this.config = config;
  }
  static {
    this.register();
  }
  async meta() {
    return this.llm.meta();
  }
  async embed(input, options) {
    const inputs = input.map((messages) => this.messagesToPrompt(messages));
    return this.llm.embed(inputs, options);
  }
  createSnapshot() {
    return {
      ...super.createSnapshot(),
      modelId: this.modelId,
      executionOptions: utils_cjs.shallowCopy(this.executionOptions),
      llm: this.llm,
      config: utils_cjs.shallowCopy(this.config)
    };
  }
  async tokenize(messages) {
    const prompt = this.messagesToPrompt(messages);
    return this.llm.tokenize(prompt);
  }
  async _generate(messages, options, run) {
    const prompt = this.messagesToPrompt(messages);
    const rawResponse = await this.llm._generate(prompt, options, run);
    return new BAMChatLLMOutput(rawResponse);
  }
  async *_stream(messages, options, run) {
    const prompt = this.messagesToPrompt(messages);
    const response = this.llm._stream(prompt, options, run);
    return yield* stream_cjs.transformAsyncIterable(response, (output) => new BAMChatLLMOutput(output));
  }
  messagesToPrompt(messages) {
    return this.config.messagesToPrompt(messages);
  }
  static fromPreset(modelId, overrides) {
    const presetFactory = chatPreset_cjs.BAMChatLLMPreset[modelId];
    if (!presetFactory) {
      throw new base_cjs.LLMError(`Model "${modelId}" does not exist in preset.`);
    }
    const preset = presetFactory();
    let parameters = preset.base.parameters ?? {};
    if (remeda.isFunction(overrides?.parameters)) {
      parameters = overrides?.parameters(parameters);
    } else if (remeda.isObjectType(overrides?.parameters)) {
      parameters = overrides?.parameters;
    }
    return new BAMChatLLM({
      config: preset.chat,
      llm: new llm_cjs.BAMLLM({
        ...preset.base,
        ...overrides,
        parameters,
        client: overrides?.client ?? new nodeSdk.Client(),
        modelId
      })
    });
  }
}

exports.BAMChatLLM = BAMChatLLM;
exports.BAMChatLLMOutput = BAMChatLLMOutput;
//# sourceMappingURL=chat.cjs.map
//# sourceMappingURL=chat.cjs.map