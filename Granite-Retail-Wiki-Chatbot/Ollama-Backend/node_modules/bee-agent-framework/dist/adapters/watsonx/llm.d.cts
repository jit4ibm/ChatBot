import { BaseLLMOutput, GenerateOptions, ExecutionOptions, LLMCache, LLMMeta, EmbeddingOptions, EmbeddingOutput, BaseLLMEvents, BaseLLMTokenizeOutput, AsyncStream } from '../../llms/base.cjs';
import { LLMEvents, LLM, LLMInput } from '../../llms/llm.cjs';
import { RestfulClient } from '../../internals/fetcher.cjs';
import { E as Emitter } from '../../emitter-DdThRYHg.cjs';
import { GetRunContext } from '../../context.cjs';
import '../../errors.cjs';
import '../../internals/types.cjs';
import '../../internals/helpers/guards.cjs';
import '../../internals/serializable.cjs';
import '../../cache/base.cjs';
import 'promise-based-task';
import '../../internals/helpers/promise.cjs';
import '@ai-zen/node-fetch-event-source';
import '@ai-zen/node-fetch-event-source/lib/cjs/fetch.js';

interface WatsonXLLMOutputMeta {
    model_id: string;
    created_at: string;
}
interface WatsonXLLMOutputResult {
    generated_text: string;
    generated_token_count: number;
    input_token_count: number;
    stop_reason?: string;
}
interface WatsonXLLMOutputConstructor {
    meta: WatsonXLLMOutputMeta;
    results: WatsonXLLMOutputResult[];
    system: Record<string, Record<string, any>[]>;
}
declare class WatsonXLLMOutput extends BaseLLMOutput {
    readonly meta: WatsonXLLMOutputMeta;
    readonly results: WatsonXLLMOutputResult[];
    constructor(content: WatsonXLLMOutputConstructor);
    getTextContent(): string;
    get finalResult(): Readonly<WatsonXLLMOutputResult>;
    merge(other: WatsonXLLMOutput): void;
    createSnapshot(): {
        results: WatsonXLLMOutputResult[];
        meta: WatsonXLLMOutputMeta;
    };
    loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void;
    toString(): string;
}
interface WatsonXLLMParameters extends GenerateOptions {
    [key: string]: any;
    decoding_method?: "sample" | "greedy";
    length_penalty?: {
        decay_factor?: number;
        start_index?: number;
    };
    max_new_tokens?: number;
    min_new_tokens?: number;
    random_seed?: number;
    stop_sequences?: string[];
    temperature?: number;
    time_limit?: number;
    top_k?: number;
    top_p?: number;
    repetition_penalty?: number;
    truncate_input_tokens?: number;
    return_options?: {
        input_text?: boolean;
        generated_tokens?: boolean;
        input_tokens?: boolean;
        token_logprobs?: boolean;
        token_ranks?: boolean;
        top_n_tokens?: boolean;
    };
    include_stop_sequence?: boolean;
    typical_p?: number;
    prompt_variables?: Record<string, any>;
}
type WatsonXLLMModerations = Record<string, any>;
interface WatsonXLLMGenerateOptions extends GenerateOptions {
    parameters?: WatsonXLLMParameters;
    moderations?: WatsonXLLMModerations;
}
interface WatsonXLLMInput {
    modelId: string;
    projectId?: string;
    spaceId?: string;
    deploymentId?: string;
    version?: string;
    apiKey?: string;
    accessToken?: string;
    baseUrl?: string;
    authBaseUrl?: string;
    region?: string;
    parameters?: WatsonXLLMParameters;
    moderations?: WatsonXLLMModerations;
    executionOptions?: ExecutionOptions;
    transform?: WatsonXLLMTransformFn;
    cache?: LLMCache<WatsonXLLMOutput>;
}
type WatsonXLLMTransformFn = (body: Record<string, any>) => Record<string, any>;
type WatsonXLLMEvents = LLMEvents<WatsonXLLMOutput>;
declare class WatsonXLLM extends LLM<WatsonXLLMOutput, WatsonXLLMGenerateOptions> {
    readonly emitter: Emitter<WatsonXLLMEvents>;
    readonly client: RestfulClient<{
        generate: string;
        generate_stream: string;
        tokenization: string;
        models: string;
        deployment: string;
        embeddings: string;
    }>;
    protected projectId: string | undefined;
    protected deploymentId: string | undefined;
    protected spaceId: string | undefined;
    protected transform: WatsonXLLMTransformFn;
    readonly moderations: WatsonXLLMModerations | undefined;
    readonly parameters: WatsonXLLMParameters;
    constructor(input: WatsonXLLMInput);
    meta(): Promise<LLMMeta>;
    embed(input: LLMInput[], options?: EmbeddingOptions): Promise<EmbeddingOutput>;
    createSnapshot(): {
        modelId: string;
        spaceId: string | undefined;
        deploymentId: string | undefined;
        projectId: string | undefined;
        parameters: WatsonXLLMParameters;
        moderations: WatsonXLLMModerations | undefined;
        executionOptions: ExecutionOptions;
        transform: WatsonXLLMTransformFn;
        client: RestfulClient<{
            generate: string;
            generate_stream: string;
            tokenization: string;
            models: string;
            deployment: string;
            embeddings: string;
        }>;
        emitter: Emitter<BaseLLMEvents<unknown, WatsonXLLMOutput>>;
        cache: LLMCache<WatsonXLLMOutput>;
    };
    loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void;
    protected _transformError(error: Error): Error;
    tokenize(input: LLMInput): Promise<BaseLLMTokenizeOutput>;
    protected _generate(input: LLMInput, options: WatsonXLLMGenerateOptions | undefined, run: GetRunContext<this>): Promise<WatsonXLLMOutput>;
    protected _stream(input: LLMInput, options: WatsonXLLMGenerateOptions | undefined, run: GetRunContext<this>): AsyncStream<WatsonXLLMOutput, void>;
    protected _rawResponseToOutput(raw: any): WatsonXLLMOutput;
}

export { WatsonXLLM, type WatsonXLLMEvents, type WatsonXLLMGenerateOptions, type WatsonXLLMInput, type WatsonXLLMModerations, WatsonXLLMOutput, type WatsonXLLMOutputConstructor, type WatsonXLLMOutputMeta, type WatsonXLLMOutputResult, type WatsonXLLMParameters };
