{"version":3,"sources":["../../../src/adapters/vertexai/llm.ts"],"names":["VertexAILLMOutput","BaseLLMOutput","chunks","constructor","chunk","push","merge","other","getTextContent","map","result","text","join","toString","createSnapshot","shallowCopy","loadSnapshot","snapshot","Object","assign","VertexAILLM","LLM","emitter","client","parameters","input","modelId","executionOptions","cache","Emitter","root","child","namespace","creator","VertexAI","project","location","register","registerVertexAI","meta","tokenLimit","Infinity","embed","options","NotImplementedError","tokenize","generativeModel","createModel","response","countTokens","contents","parts","role","Role","USER","tokensCount","totalTokens","_generate","run","guided","json","responses","signalRace","generateContent","signal","processContentResponse","metadata","tokenCount","getTokenCount","_stream","generateContentStream","stream","aborted","throwIfAborted"],"mappings":";;;;;;;;;;;;AA2CO,MAAMA,0BAA0BC,aAAAA,CAAAA;EA3CvC;;;AA4CkBC,EAAAA,MAAAA,GAA6B,EAAA;AAE7CC,EAAAA,WAAAA,CAAYC,KAAyB,EAAA;AACnC,IAAK,KAAA,EAAA;AACL,IAAKF,IAAAA,CAAAA,MAAAA,CAAOG,KAAKD,KAAAA,CAAAA;AACnB;AAEAE,EAAAA,KAAAA,CAAMC,KAAgC,EAAA;AACpC,IAAA,IAAA,CAAKL,MAAOG,CAAAA,IAAAA,CAAI,GAAIE,KAAAA,CAAML,MAAM,CAAA;AAClC;EAEAM,cAAyB,GAAA;AACvB,IAAO,OAAA,IAAA,CAAKN,OAAOO,GAAI,CAAA,CAACC,WAAWA,MAAOC,CAAAA,IAAI,CAAEC,CAAAA,IAAAA,CAAK,EAAA,CAAA;AACvD;EAEAC,QAAmB,GAAA;AACjB,IAAA,OAAO,KAAKL,cAAc,EAAA;AAC5B;EAEAM,cAAiB,GAAA;AACf,IAAO,OAAA;MAAEZ,MAAQa,EAAAA,WAAAA,CAAY,KAAKb,MAAM;AAAE,KAAA;AAC5C;AAEAc,EAAAA,YAAAA,CAAaC,QAAwD,EAAA;AACnEC,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMF,QAAAA,CAAAA;AACtB;AACF;AAcO,MAAMG,oBAAoBC,GAAAA,CAAAA;EApFjC;;;;AAqFkBC,EAAAA,OAAAA;AAKNC,EAAAA,MAAAA;AACAC,EAAAA,UAAAA;AAEVrB,EAAAA,WAAAA,CAA+BsB,KAAyB,EAAA;AACtD,IAAA,KAAA,CAAMA,KAAMC,CAAAA,OAAAA,EAASD,KAAME,CAAAA,gBAAAA,EAAkBF,MAAMG,KAAK,CAAA,EAAA,IAD3BH,CAAAA,KAAAA,GAAAA,KAAAA,EAAAA,IAAAA,CARfH,OAAUO,GAAAA,OAAAA,CAAQC,KAAKC,KAAyB,CAAA;MAC9DC,SAAW,EAAA;AAAC,QAAA,UAAA;AAAY,QAAA;;MACxBC,OAAS,EAAA;KACX,CAAA;AAOE,IAAA,IAAA,CAAKT,aAAaC,KAAMD,CAAAA,UAAAA;AACxB,IAAA,IAAA,CAAKD,MACHE,GAAAA,KAAAA,CAAMF,MAAU,IAAA,IAAIW,QAAS,CAAA;AAAEC,MAAAA,OAAAA,EAASV,KAAMU,CAAAA,OAAAA;AAASC,MAAAA,QAAAA,EAAUX,KAAMW,CAAAA;KAAS,CAAA;AACpF;EAEA;AACE,IAAA,IAAA,CAAKC,QAAQ,EAAA;AACbC,IAAAA,gBAAAA,EAAAA;AACF;AAEA,EAAA,MAAMC,IAAyB,GAAA;AAC7B,IAAO,OAAA;MAAEC,UAAYC,EAAAA;AAAS,KAAA;AAChC;;EAGA,MAAMC,KAAAA,CAAMjB,OAAmBkB,OAAsD,EAAA;AACnF,IAAA,MAAM,IAAIC,mBAAAA,EAAAA;AACZ;AAEA,EAAA,MAAMC,SAASpB,KAAiD,EAAA;AAC9D,IAAA,MAAMqB,eAAkBC,GAAAA,WAAAA,CAAY,IAAKxB,CAAAA,MAAAA,EAAQ,KAAKG,OAAO,CAAA;AAC7D,IAAMsB,MAAAA,QAAAA,GAAW,MAAMF,eAAAA,CAAgBG,WAAY,CAAA;MACjDC,QAAU,EAAA;AAAC,QAAA;UAAEC,KAAO,EAAA;AAAC,YAAA;cAAExC,IAAMc,EAAAA;AAAM;;AAAI2B,UAAAA,IAAAA,EAAMC,IAAKC,CAAAA;AAAK;;KACzD,CAAA;AACA,IAAO,OAAA;AACLC,MAAAA,WAAAA,EAAaP,QAASQ,CAAAA;AACxB,KAAA;AACF;EAEA,MAAgBC,SAAAA,CACdhC,KACAkB,EAAAA,OAAAA,EACAe,GAC4B,EAAA;AAC5B,IAAMZ,MAAAA,eAAAA,GAAkBC,WACtB,CAAA,IAAA,CAAKxB,MACL,EAAA,IAAA,CAAKG,SACLiB,OAAQgB,CAAAA,MAAAA,EAAQC,IAChB,EAAA,IAAA,CAAKpC,UAAU,CAAA;AAEjB,IAAMqC,MAAAA,SAAAA,GAAY,MAAMC,UAAW,CAAA,MAAMhB,gBAAgBiB,eAAgBtC,CAAAA,KAAAA,CAAQiC,EAAAA,GAAAA,CAAIM,MAAM,CAAA;AAC3F,IAAA,MAAMtD,MAA2B,GAAA;MAC/BC,IAAMsD,EAAAA,sBAAAA,CAAuBJ,UAAUb,QAAQ,CAAA;MAC/CkB,QAAU,EAAA;QAAEC,UAAYC,EAAAA,aAAAA,CAAcP,UAAUb,QAAQ;AAAE;AAC5D,KAAA;AACA,IAAO,OAAA,IAAIhD,kBAAkBU,MAAAA,CAAAA;AAC/B;EAEA,OAAiB2D,OAAAA,CACf5C,KACAkB,EAAAA,OAAAA,EACAe,GACsC,EAAA;AACtC,IAAMZ,MAAAA,eAAAA,GAAkBC,WACtB,CAAA,IAAA,CAAKxB,MACL,EAAA,IAAA,CAAKG,SACLiB,OAASgB,EAAAA,MAAAA,EAAQC,IACjB,EAAA,IAAA,CAAKpC,UAAU,CAAA;AAEjB,IAAA,MAAMwB,QAAW,GAAA,MAAMF,eAAgBwB,CAAAA,qBAAAA,CAAsB7C,KAAAA,CAAAA;AAC7D,IAAiBrB,WAAAA,MAAAA,KAAAA,IAAS4C,SAASuB,MAAQ,EAAA;AACzC,MAAI5B,IAAAA,OAAAA,EAASqB,QAAQQ,OAAS,EAAA;AAC5B,QAAA;AACF;AACA,MAAA,MAAM9D,MAA2B,GAAA;AAC/BC,QAAAA,IAAAA,EAAMsD,uBAAuB7D,KAAAA,CAAAA;QAC7B8D,QAAU,EAAA;AAAEC,UAAAA,UAAAA,EAAYC,cAAchE,KAAAA;AAAO;AAC/C,OAAA;AACA,MAAM,MAAA,IAAIJ,kBAAkBU,MAAAA,CAAAA;AAC9B;AACAgD,IAAAA,GAAAA,CAAIM,OAAOS,cAAc,EAAA;AAC3B;EAEA3D,cAAiB,GAAA;AACf,IAAO,OAAA;AACL,MAAA,GAAG,MAAMA,cAAAA,EAAAA;MACTW,KAAOV,EAAAA,WAAAA,CAAY,KAAKU,KAAK,CAAA;AAC7BF,MAAAA,MAAAA,EAAQ,IAAKA,CAAAA,MAAAA;AACbC,MAAAA,UAAAA,EAAY,IAAKA,CAAAA;AACnB,KAAA;AACF;AAEAR,EAAAA,YAAAA,CAAa,EAAES,KAAAA,EAAO,GAAGR,QAAAA,EAAoD,EAAA;AAC3E,IAAA,KAAA,CAAMD,aAAaC,QAAAA,CAAAA;AACnBC,IAAAA,MAAAA,CAAOC,OAAO,IAAM,EAAA;AAAEM,MAAAA;KAAM,CAAA;AAC9B;AACF","file":"llm.js","sourcesContent":["/**\n * Copyright 2024 IBM Corp.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LLM, LLMEvents, LLMInput } from \"@/llms/llm.js\";\nimport {\n  AsyncStream,\n  BaseLLMOutput,\n  BaseLLMTokenizeOutput,\n  EmbeddingOptions,\n  EmbeddingOutput,\n  ExecutionOptions,\n  GenerateOptions,\n  LLMCache,\n  LLMMeta,\n  StreamGenerateOptions,\n} from \"@/llms/base.js\";\nimport { shallowCopy } from \"@/serializer/utils.js\";\nimport type { GetRunContext } from \"@/context.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport { VertexAI, BaseModelParams as Params } from \"@google-cloud/vertexai\";\nimport { Role } from \"@/llms/primitives/message.js\";\nimport { signalRace } from \"@/internals/helpers/promise.js\";\nimport { processContentResponse, getTokenCount, registerVertexAI, createModel } from \"./utils.js\";\nimport { NotImplementedError } from \"@/errors.js\";\n\ninterface VertexAILLMChunk {\n  text: string;\n  metadata: Record<string, any>;\n}\n\nexport class VertexAILLMOutput extends BaseLLMOutput {\n  public readonly chunks: VertexAILLMChunk[] = [];\n\n  constructor(chunk: VertexAILLMChunk) {\n    super();\n    this.chunks.push(chunk);\n  }\n\n  merge(other: VertexAILLMOutput): void {\n    this.chunks.push(...other.chunks);\n  }\n\n  getTextContent(): string {\n    return this.chunks.map((result) => result.text).join(\"\");\n  }\n\n  toString(): string {\n    return this.getTextContent();\n  }\n\n  createSnapshot() {\n    return { chunks: shallowCopy(this.chunks) };\n  }\n\n  loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void {\n    Object.assign(this, snapshot);\n  }\n}\n\nexport interface VertexAILLMInput {\n  modelId: string;\n  project: string;\n  location: string;\n  client?: VertexAI;\n  executionOptions?: ExecutionOptions;\n  cache?: LLMCache<VertexAILLMOutput>;\n  parameters?: Params;\n}\n\nexport type VertexAILLMEvents = LLMEvents<VertexAILLMOutput>;\n\nexport class VertexAILLM extends LLM<VertexAILLMOutput> {\n  public readonly emitter = Emitter.root.child<VertexAILLMEvents>({\n    namespace: [\"vertexai\", \"llm\"],\n    creator: this,\n  });\n\n  protected client: VertexAI;\n  protected parameters?: Params;\n\n  constructor(protected readonly input: VertexAILLMInput) {\n    super(input.modelId, input.executionOptions, input.cache);\n    this.parameters = input.parameters;\n    this.client =\n      input.client ?? new VertexAI({ project: input.project, location: input.location });\n  }\n\n  static {\n    this.register();\n    registerVertexAI();\n  }\n\n  async meta(): Promise<LLMMeta> {\n    return { tokenLimit: Infinity };\n  }\n\n  // eslint-disable-next-line unused-imports/no-unused-vars\n  async embed(input: LLMInput[], options?: EmbeddingOptions): Promise<EmbeddingOutput> {\n    throw new NotImplementedError();\n  }\n\n  async tokenize(input: LLMInput): Promise<BaseLLMTokenizeOutput> {\n    const generativeModel = createModel(this.client, this.modelId);\n    const response = await generativeModel.countTokens({\n      contents: [{ parts: [{ text: input }], role: Role.USER }],\n    });\n    return {\n      tokensCount: response.totalTokens,\n    };\n  }\n\n  protected async _generate(\n    input: LLMInput,\n    options: GenerateOptions,\n    run: GetRunContext<this>,\n  ): Promise<VertexAILLMOutput> {\n    const generativeModel = createModel(\n      this.client,\n      this.modelId,\n      options.guided?.json,\n      this.parameters,\n    );\n    const responses = await signalRace(() => generativeModel.generateContent(input), run.signal);\n    const result: VertexAILLMChunk = {\n      text: processContentResponse(responses.response),\n      metadata: { tokenCount: getTokenCount(responses.response) },\n    };\n    return new VertexAILLMOutput(result);\n  }\n\n  protected async *_stream(\n    input: LLMInput,\n    options: Partial<StreamGenerateOptions>,\n    run: GetRunContext<this>,\n  ): AsyncStream<VertexAILLMOutput, void> {\n    const generativeModel = createModel(\n      this.client,\n      this.modelId,\n      options?.guided?.json,\n      this.parameters,\n    );\n    const response = await generativeModel.generateContentStream(input);\n    for await (const chunk of response.stream) {\n      if (options?.signal?.aborted) {\n        break;\n      }\n      const result: VertexAILLMChunk = {\n        text: processContentResponse(chunk),\n        metadata: { tokenCount: getTokenCount(chunk) },\n      };\n      yield new VertexAILLMOutput(result);\n    }\n    run.signal.throwIfAborted();\n  }\n\n  createSnapshot() {\n    return {\n      ...super.createSnapshot(),\n      input: shallowCopy(this.input),\n      client: this.client,\n      parameters: this.parameters,\n    };\n  }\n\n  loadSnapshot({ input, ...snapshot }: ReturnType<typeof this.createSnapshot>) {\n    super.loadSnapshot(snapshot);\n    Object.assign(this, { input });\n  }\n}\n"]}