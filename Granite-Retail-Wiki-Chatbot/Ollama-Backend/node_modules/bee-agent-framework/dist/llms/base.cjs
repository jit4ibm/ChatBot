'use strict';

var errors_cjs = require('../errors.cjs');
var serializable_cjs = require('../internals/serializable.cjs');
var cancellation_cjs = require('../internals/helpers/cancellation.cjs');
var context_cjs = require('../context.cjs');
var utils_cjs = require('../serializer/utils.cjs');
var retry_cjs = require('../internals/helpers/retry.cjs');
var promise_cjs = require('../internals/helpers/promise.cjs');
var nullCache_cjs = require('../cache/nullCache.cjs');
var decoratorCache_cjs = require('../cache/decoratorCache.cjs');
var remeda = require('remeda');
var promiseBasedTask = require('promise-based-task');
var config_cjs = require('../instrumentation/config.cjs');
var createTelemetryMiddleware_cjs = require('../instrumentation/create-telemetry-middleware.cjs');

var __defProp = Object.defineProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
class LLMError extends errors_cjs.FrameworkError {
  static {
    __name(this, "LLMError");
  }
}
class LLMFatalError extends LLMError {
  static {
    __name(this, "LLMFatalError");
  }
  constructor(message, errors) {
    super(message, errors, {
      isRetryable: false,
      isFatal: true
    });
  }
}
class LLMOutputError extends LLMFatalError {
  static {
    __name(this, "LLMOutputError");
  }
}
class BaseLLMOutput extends serializable_cjs.Serializable {
  static {
    __name(this, "BaseLLMOutput");
  }
  mergeImmutable(other) {
    const newInstance = this.clone();
    newInstance.merge(other);
    return newInstance;
  }
}
class BaseLLM extends serializable_cjs.Serializable {
  static {
    __name(this, "BaseLLM");
  }
  modelId;
  executionOptions;
  cache;
  constructor(modelId, executionOptions = {}, cache = new nullCache_cjs.NullCache()) {
    super(), this.modelId = modelId, this.executionOptions = executionOptions, this.cache = cache;
  }
  generate(input, options = {}) {
    input = utils_cjs.shallowCopy(input);
    options = utils_cjs.shallowCopy(options);
    return context_cjs.RunContext.enter(this, {
      params: [
        input,
        options
      ],
      signal: options?.signal
    }, async (run) => {
      const cacheEntry = await this.createCacheAccessor(input, options);
      try {
        await run.emitter.emit("start", {
          input,
          options
        });
        if (options?.stream) {
          const chunks = [];
          const controller = cancellation_cjs.createAbortController(options?.signal);
          const tokenEmitter = run.emitter.child({
            groupId: "tokens"
          });
          for await (const chunk of cacheEntry.value ?? this._stream(input, {
            ...options,
            signal: controller.signal
          }, run)) {
            if (controller.signal.aborted) {
              continue;
            }
            chunks.push(chunk);
            await tokenEmitter.emit("newToken", {
              value: chunk,
              callbacks: {
                abort: /* @__PURE__ */ __name(() => controller.abort(), "abort")
              }
            });
          }
          const result2 = this._mergeChunks(chunks);
          await run.emitter.emit("success", {
            value: result2
          });
          cacheEntry.resolve(chunks);
          return result2;
        }
        const result = cacheEntry?.value?.at(0) || await retry_cjs.pRetry(() => this._generate(input, options, run), {
          retries: this.executionOptions.maxRetries || 0,
          ...options,
          signal: run.signal
        });
        await run.emitter.emit("success", {
          value: result
        });
        cacheEntry.resolve([
          result
        ]);
        return result;
      } catch (error) {
        await run.emitter.emit("error", {
          input,
          error,
          options
        });
        await cacheEntry.reject(error);
        if (error instanceof LLMError) {
          throw error;
        } else {
          throw new LLMError(`LLM has occurred an error.`, [
            error
          ]);
        }
      } finally {
        await run.emitter.emit("finish", null);
      }
    }).middleware(config_cjs.INSTRUMENTATION_ENABLED ? createTelemetryMiddleware_cjs.createTelemetryMiddleware() : remeda.doNothing());
  }
  async *stream(input, options = {}) {
    input = utils_cjs.shallowCopy(input);
    options = utils_cjs.shallowCopy(options);
    return yield* promise_cjs.emitterToGenerator(async ({ emit }) => {
      return context_cjs.RunContext.enter(this, {
        params: [
          input,
          options
        ],
        signal: options?.signal
      }, async (run) => {
        const cacheEntry = await this.createCacheAccessor(input, options);
        try {
          await run.emitter.emit("start", {
            input,
            options
          });
          const tokenEmitter = run.emitter.child({
            groupId: "tokens"
          });
          const chunks = [];
          const controller = cancellation_cjs.createAbortController(options?.signal);
          for await (const chunk of cacheEntry.value || this._stream(input, {
            ...options,
            signal: controller.signal
          }, run)) {
            if (controller.signal.aborted) {
              continue;
            }
            chunks.push(chunk);
            await tokenEmitter.emit("newToken", {
              value: chunk,
              callbacks: {
                abort: /* @__PURE__ */ __name(() => controller.abort(), "abort")
              }
            });
            emit(chunk);
          }
          const result = this._mergeChunks(chunks);
          await run.emitter.emit("success", {
            value: result
          });
          cacheEntry.resolve(chunks);
        } catch (error) {
          await run.emitter.emit("error", {
            input,
            error,
            options
          });
          await cacheEntry.reject(error);
          if (error instanceof LLMError) {
            throw error;
          } else {
            throw new LLMError(`LLM has occurred an error.`, [
              error
            ]);
          }
        } finally {
          await run.emitter.emit("finish", null);
        }
      }).middleware(config_cjs.INSTRUMENTATION_ENABLED ? createTelemetryMiddleware_cjs.createTelemetryMiddleware() : remeda.doNothing());
    });
  }
  _mergeChunks(chunks) {
    if (chunks.length === 0) {
      throw new LLMOutputError("Cannot merge empty chunks!");
    }
    return chunks.reduce((prev, cur) => prev.mergeImmutable(cur));
  }
  static cast(value) {
  }
  static castInput(value) {
  }
  static castOutput(value) {
  }
  createSnapshot() {
    return {
      modelId: this.modelId,
      executionOptions: utils_cjs.shallowCopy(this.executionOptions),
      emitter: this.emitter,
      cache: this.cache
    };
  }
  loadSnapshot(snapshot) {
    Object.assign(this, snapshot);
  }
  async createCacheAccessor(input, options, ...extra) {
    const key = decoratorCache_cjs.ObjectHashKeyFn(input, remeda.omit(options ?? {}, [
      "signal"
    ]), ...extra);
    const value = await this.cache.get(key);
    const isNew = value === void 0;
    let task = null;
    if (isNew) {
      task = new promiseBasedTask.Task();
      await this.cache.set(key, task);
    }
    return {
      key,
      value,
      resolve: /* @__PURE__ */ __name((value2) => {
        task?.resolve?.(Array.isArray(value2) ? value2 : [
          value2
        ]);
      }, "resolve"),
      reject: /* @__PURE__ */ __name(async (error) => {
        task?.reject?.(error);
        if (isNew) {
          await this.cache.delete(key);
        }
      }, "reject")
    };
  }
}

exports.BaseLLM = BaseLLM;
exports.BaseLLMOutput = BaseLLMOutput;
exports.LLMError = LLMError;
exports.LLMFatalError = LLMFatalError;
exports.LLMOutputError = LLMOutputError;
//# sourceMappingURL=base.cjs.map
//# sourceMappingURL=base.cjs.map