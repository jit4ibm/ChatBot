{"version":3,"sources":["../../../../src/adapters/langchain/llms/chat.ts"],"names":["LangChainChatLLMOutput","ChatLLMOutput","constructor","messages","meta","register","merge","other","push","Object","assign","omitUndefined","getTextContent","map","msg","text","join","toString","createSnapshot","shallowCopy","loadSnapshot","snapshot","LangChainChatLLM","ChatLLM","emitter","parameters","lcLLM","modelMeta","executionOptions","cache","_modelType","Emitter","root","child","namespace","creator","invocationParams","tokenLimit","Infinity","embed","input","options","NotImplementedError","tokenize","tokensCount","getNumTokens","mappers","roleMapper","Map","Role","SYSTEM","ASSISTANT","USER","toLCMessage","message","LCMChatMessage","role","content","response_metadata","fromLCMessage","getProp","_getType","filter","type","BaseMessage","of","has","get","_generate","run","lcMessages","response","invoke","lc","signal","_stream","_streamResponseChunks","chunk","modelId","JSON","stringify","toJSON","state","includes","GenAIChatModel","fromJSON","load"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAgDO,MAAMA,+BAA+BC,sBAAAA,CAAAA;AAAAA,EAAAA;;;;;EAC1CC,WACSC,CAAAA,QAAAA,EACAC,IAA4B,GAAA,EACnC,EAAA;AACA,IAAA,KAAA,EAAK,EAAA,IAAA,CAHED,QAAAA,GAAAA,QAAAA,EAAAA,KACAC,IAAAA,GAAAA,IAAAA;AAGT;EAEA;AACE,IAAA,IAAA,CAAKC,QAAQ,EAAA;AACf;AAEAC,EAAAA,KAAAA,CAAMC,KAAqC,EAAA;AACzC,IAAA,IAAA,CAAKJ,QAASK,CAAAA,IAAAA,CAAI,GAAID,KAAAA,CAAMJ,QAAQ,CAAA;AACpCM,IAAAA,MAAAA,CAAOC,OAAO,IAAKN,CAAAA,IAAAA,EAAMO,wBAAcJ,CAAAA,KAAAA,CAAMH,IAAI,CAAA,CAAA;AACnD;EAEAQ,cAAyB,GAAA;AACvB,IAAO,OAAA,IAAA,CAAKT,SAASU,GAAI,CAAA,CAACC,QAAQA,GAAIC,CAAAA,IAAI,CAAEC,CAAAA,IAAAA,CAAK,EAAA,CAAA;AACnD;EAEAC,QAAmB,GAAA;AACjB,IAAA,OAAO,KAAKL,cAAc,EAAA;AAC5B;EAEAM,cAAiB,GAAA;AACf,IAAO,OAAA;MACLf,QAAUgB,EAAAA,qBAAAA,CAAY,KAAKhB,QAAQ,CAAA;MACnCC,IAAMe,EAAAA,qBAAAA,CAAY,KAAKf,IAAI;AAC7B,KAAA;AACF;AAEAgB,EAAAA,YAAAA,CAAaC,QAAwD,EAAA;AACnEZ,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMW,QAAAA,CAAAA;AACtB;AACF;AAOO,MAAMC,yBAGHC,gBAAAA,CAAAA;AAAAA,EAAAA;;;;;AACQC,EAAAA,OAAAA;AAIAC,EAAAA,UAAAA;EAEhBvB,WACkBwB,CAAAA,KAAAA,EACNC,SACVC,EAAAA,gBAAAA,EACAC,KACA,EAAA;AACA,IAAA,KAAA,CAAMH,MAAMI,UAAU,EAAA,EAAIF,gBAAkBC,EAAAA,KAAAA,GAAAA,IAL5BH,CAAAA,KAAAA,GAAAA,KAAAA,EAAAA,IAAAA,CACNC,YAAAA,SAAAA,EAAAA,IAAAA,CARIH,OAAUO,GAAAA,mBAAAA,CAAQC,KAAKC,KAA8B,CAAA;MACnEC,SAAW,EAAA;AAAC,QAAA,WAAA;AAAa,QAAA;;MACzBC,OAAS,EAAA;KACX,CAAA;AAUE,IAAKV,IAAAA,CAAAA,UAAAA,GAAaC,MAAMU,gBAAgB,EAAA;AAC1C;EAEA;AACE,IAAA,IAAA,CAAK/B,QAAQ,EAAA;AACf;AAEA,EAAA,MAAMD,IAAO,GAAA;AACX,IAAA,IAAI,KAAKuB,SAAW,EAAA;AAClB,MAAA,OAAO,IAAKA,CAAAA,SAAAA;AACd;AAEA,IAAO,OAAA;MACLU,UAAYC,EAAAA;AACd,KAAA;AACF;;EAGA,MAAMC,KAAAA,CAAMC,OAAwBC,OAAsD,EAAA;AACxF,IAAA,MAAM,IAAIC,8BAAAA,EAAAA;AACZ;AAEA,EAAA,MAAMC,SAASH,KAAsD,EAAA;AACnE,IAAO,OAAA;AACLI,MAAAA,WAAAA,EAAa,MAAM,IAAA,CAAKlB,KAAMmB,CAAAA,YAAAA,CAAaL,KAAAA;AAC7C,KAAA;AACF;AAEA,EAAA,IACcM,OAAU,GAAA;AACtB,IAAMC,MAAAA,UAAAA,uBAAiBC,GAAoC,CAAA;AACzD,MAAA;AAAC,QAAA,QAAA;QAAUC,gBAAKC,CAAAA;;AAChB,MAAA;AAAC,QAAA,WAAA;QAAaD,gBAAKE,CAAAA;;AACnB,MAAA;AAAC,QAAA,IAAA;QAAMF,gBAAKE,CAAAA;;AACZ,MAAA;AAAC,QAAA,SAAA;QAAWF,gBAAKE,CAAAA;;AACjB,MAAA;AAAC,QAAA,UAAA;QAAYF,gBAAKE,CAAAA;;AAClB,MAAA;AAAC,QAAA,MAAA;QAAQF,gBAAKE,CAAAA;;AACd,MAAA;AAAC,QAAA,OAAA;QAASF,gBAAKG,CAAAA;;AACf,MAAA;AAAC,QAAA,MAAA;QAAQH,gBAAKE,CAAAA;;AACf,KAAA,CAAA;AAED,IAAO,OAAA;AACLE,MAAAA,WAAAA,CAAYC,OAAoB,EAAA;AAC9B,QAAA,OAAO,IAAIC,oBAAe,CAAA;AACxBC,UAAAA,IAAAA,EAAMF,OAAQE,CAAAA,IAAAA;AACdC,UAAAA,OAAAA,EAASH,OAAQvC,CAAAA,IAAAA;AACjB2C,UAAAA,iBAAAA,EAAmBJ,OAAQlD,CAAAA;SAC7B,CAAA;AACF,OAAA;AACAuD,MAAAA,aAAAA,CAAcL,OAAuC,EAAA;AACnD,QAAME,MAAAA,IAAAA,GAAeI,mBAAQN,OAAS,EAAA;AAAC,UAAA;AAASA,SAAAA,EAAAA,OAAAA,CAAQO,UAAQ,CAAA;AAChE,QAAM9C,MAAAA,IAAAA,GACJ,OAAOuC,OAAQG,CAAAA,OAAAA,KAAY,WACvBH,OAAQG,CAAAA,OAAAA,GACRH,OAAQG,CAAAA,OAAAA,CACLK,MACC,CAAA,CAAChD,QAA0DA,GAAIiD,CAAAA,IAAAA,KAAS,MAAA,CAAA,CAEzElD,GAAI,CAAA,CAACC,QAA4BA,GAAIC,CAAAA,IAAI,CACzCC,CAAAA,IAAAA,CAAK,IAAA,CAAA;AAEd,QAAA,OAAOgD,wBAAYC,EAAG,CAAA;UACpBT,IAAMT,EAAAA,UAAAA,CAAWmB,IAAIV,IAAAA,CAAAA,GAAQT,WAAWoB,GAAIX,CAAAA,IAAAA,IAASP,gBAAKE,CAAAA,SAAAA;AAC1DpC,UAAAA;SACF,CAAA;AACF;AACF,KAAA;AACF;EAEA,MAAgBqD,SAAAA,CACd5B,KACAC,EAAAA,OAAAA,EACA4B,GACiC,EAAA;AACjC,IAAMC,MAAAA,UAAAA,GAAa9B,MAAM3B,GAAI,CAAA,CAACC,QAAQ,IAAKgC,CAAAA,OAAAA,CAAQO,WAAYvC,CAAAA,GAAAA,CAAAA,CAAAA;AAC/D,IAAA,MAAMyD,QAAW,GAAA,MAAM,IAAK7C,CAAAA,KAAAA,CAAM8C,OAAOF,UAAY,EAAA;AACnD,MAAA,GAAG7B,OAASgC,EAAAA,EAAAA;AACZC,MAAAA,MAAAA,EAAQL,GAAIK,CAAAA;KACd,CAAA;AAEA,IAAA,OAAO,IAAI1E,sBACT,CAAA;MAAC,IAAK8C,CAAAA,OAAAA,CAAQa,cAAcY,QAAAA;AAC5BA,KAAAA,EAAAA,QAAAA,CAASb,iBAAiB,CAAA;AAE9B;EAEA,OAAiBiB,OAAAA,CACfnC,KACAC,EAAAA,OAAAA,EACA4B,GACqC,EAAA;AACrC,IAAMC,MAAAA,UAAAA,GAAa9B,MAAM3B,GAAI,CAAA,CAACC,QAAQ,IAAKgC,CAAAA,OAAAA,CAAQO,WAAYvC,CAAAA,GAAAA,CAAAA,CAAAA;AAC/D,IAAA,MAAMyD,QAAW,GAAA,IAAA,CAAK7C,KAAMkD,CAAAA,qBAAAA,CAAsBN,UAAY,EAAA;AAC5D,MAAA,GAAG7B,OAASgC,EAAAA,EAAAA;AACZC,MAAAA,MAAAA,EAAQL,GAAIK,CAAAA;KACd,CAAA;AACA,IAAA,WAAA,MAAiBG,SAASN,QAAU,EAAA;AAClC,MAAA,MAAM,IAAIvE,sBACR,CAAA;QAAC,IAAK8C,CAAAA,OAAAA,CAAQa,aAAckB,CAAAA,KAAAA,CAAMvB,OAAO;AACzCuB,OAAAA,EAAAA,KAAAA,CAAMvB,QAAQI,iBAAiB,CAAA;AAEnC;AACF;EAEAxC,cAAiB,GAAA;AACf,IAAO,OAAA;AACL,MAAA,GAAG,MAAMA,cAAAA,EAAAA;AACT4D,MAAAA,OAAAA,EAAS,IAAKA,CAAAA,OAAAA;AACdnD,MAAAA,SAAAA,EAAW,IAAKA,CAAAA,SAAAA;MAChBF,UAAYN,EAAAA,qBAAAA,CAAY,KAAKM,UAAU,CAAA;MACvCG,gBAAkBT,EAAAA,qBAAAA,CAAY,KAAKS,gBAAgB,CAAA;AACnDF,MAAAA,KAAAA,EAAOqD,IAAKC,CAAAA,SAAAA,CAAU,IAAKtD,CAAAA,KAAAA,CAAMuD,QAAM;AACzC,KAAA;AACF;AAEA,EAAA,MAAM7D,YAAa,CAAA,EAAEM,KAAO,EAAA,GAAGwD,OAAiD,EAAA;AAC9E,IAAA,KAAA,CAAM9D,aAAa8D,KAAAA,CAAAA;AACnBzE,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMwE,KAAO,EAAA;AACzBxD,MAAAA,KAAAA,EAAO,OAAO,YAAA;AACZ,QAAIA,IAAAA,KAAAA,CAAMyD,QAAS,CAAA,6BAAA,CAAgC,EAAA;AACjD,UAAA,MAAM,EAAEC,cAAAA,EAAmB,GAAA,MAAM,OAAO,uCAAA,CAAA;AACxC,UAAOA,OAAAA,cAAAA,CAAeC,SAAS3D,KAAAA,CAAAA;AACjC;AAEA,QAAO,OAAA,MAAM4D,UAAK5D,KAAAA,CAAAA;OACpB;KACF,CAAA;AACF;AACF","file":"chat.cjs","sourcesContent":["/**\n * Copyright 2024 IBM Corp.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AsyncStream,\n  BaseLLMTokenizeOutput,\n  EmbeddingOptions,\n  EmbeddingOutput,\n  ExecutionOptions,\n  GenerateOptions,\n  LLMCache,\n  LLMMeta,\n} from \"@/llms/base.js\";\nimport { shallowCopy } from \"@/serializer/utils.js\";\nimport { load } from \"@langchain/core/load\";\nimport {\n  BaseChatModel,\n  BaseChatModelCallOptions,\n} from \"@langchain/core/language_models/chat_models\";\nimport { ChatLLM, ChatLLMGenerateEvents, ChatLLMOutput } from \"@/llms/chat.js\";\nimport { BaseMessage, Role, RoleType } from \"@/llms/primitives/message.js\";\nimport {\n  BaseMessageChunk,\n  BaseMessage as LCBaseMessage,\n  ChatMessage as LCMChatMessage,\n  MessageContentComplex,\n  MessageContentText,\n  MessageType,\n} from \"@langchain/core/messages\";\nimport { Cache } from \"@/cache/decoratorCache.js\";\nimport { getProp, omitUndefined } from \"@/internals/helpers/object.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport { GetRunContext } from \"@/context.js\";\nimport { NotImplementedError } from \"@/errors.js\";\n\nexport class LangChainChatLLMOutput extends ChatLLMOutput {\n  constructor(\n    public messages: BaseMessage[],\n    public meta: Record<string, any> = {},\n  ) {\n    super();\n  }\n\n  static {\n    this.register();\n  }\n\n  merge(other: LangChainChatLLMOutput): void {\n    this.messages.push(...other.messages);\n    Object.assign(this.meta, omitUndefined(other.meta));\n  }\n\n  getTextContent(): string {\n    return this.messages.map((msg) => msg.text).join(\"\");\n  }\n\n  toString(): string {\n    return this.getTextContent();\n  }\n\n  createSnapshot() {\n    return {\n      messages: shallowCopy(this.messages),\n      meta: shallowCopy(this.meta),\n    };\n  }\n\n  loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void {\n    Object.assign(this, snapshot);\n  }\n}\n\nexport type LangChainChatLLMParameters = Record<string, any>;\ntype MergedCallOptions<T> = { lc: T } & GenerateOptions;\n\nexport type LangChainChatLLMEvents = ChatLLMGenerateEvents<LangChainChatLLMOutput>;\n\nexport class LangChainChatLLM<\n  CallOptions extends BaseChatModelCallOptions,\n  OutputMessageType extends BaseMessageChunk,\n> extends ChatLLM<LangChainChatLLMOutput, MergedCallOptions<CallOptions>> {\n  public readonly emitter = Emitter.root.child<LangChainChatLLMEvents>({\n    namespace: [\"langchain\", \"chat_llm\"],\n    creator: this,\n  });\n  public readonly parameters: any;\n\n  constructor(\n    public readonly lcLLM: BaseChatModel<CallOptions, OutputMessageType>,\n    protected modelMeta?: LLMMeta,\n    executionOptions?: ExecutionOptions,\n    cache?: LLMCache<LangChainChatLLMOutput>,\n  ) {\n    super(lcLLM._modelType(), executionOptions, cache);\n    this.parameters = lcLLM.invocationParams();\n  }\n\n  static {\n    this.register();\n  }\n\n  async meta() {\n    if (this.modelMeta) {\n      return this.modelMeta;\n    }\n\n    return {\n      tokenLimit: Infinity,\n    };\n  }\n\n  // eslint-disable-next-line unused-imports/no-unused-vars\n  async embed(input: BaseMessage[][], options?: EmbeddingOptions): Promise<EmbeddingOutput> {\n    throw new NotImplementedError();\n  }\n\n  async tokenize(input: BaseMessage[]): Promise<BaseLLMTokenizeOutput> {\n    return {\n      tokensCount: await this.lcLLM.getNumTokens(input),\n    };\n  }\n\n  @Cache()\n  protected get mappers() {\n    const roleMapper = new Map<MessageType | string, RoleType>([\n      [\"system\", Role.SYSTEM],\n      [\"assistant\", Role.ASSISTANT],\n      [\"ai\", Role.ASSISTANT],\n      [\"generic\", Role.ASSISTANT],\n      [\"function\", Role.ASSISTANT],\n      [\"tool\", Role.ASSISTANT],\n      [\"human\", Role.USER],\n      [\"tool\", Role.ASSISTANT],\n    ]);\n\n    return {\n      toLCMessage(message: BaseMessage): LCBaseMessage {\n        return new LCMChatMessage({\n          role: message.role,\n          content: message.text,\n          response_metadata: message.meta,\n        });\n      },\n      fromLCMessage(message: LCBaseMessage | LCMChatMessage): BaseMessage {\n        const role: string = getProp(message, [\"role\"], message._getType());\n        const text: string =\n          typeof message.content === \"string\"\n            ? message.content\n            : message.content\n                .filter(\n                  (msg: MessageContentComplex): msg is MessageContentText => msg.type === \"text\",\n                )\n                .map((msg: MessageContentText) => msg.text)\n                .join(\"\\n\");\n\n        return BaseMessage.of({\n          role: roleMapper.has(role) ? roleMapper.get(role)! : Role.ASSISTANT,\n          text,\n        });\n      },\n    };\n  }\n\n  protected async _generate(\n    input: BaseMessage[],\n    options: MergedCallOptions<CallOptions>,\n    run: GetRunContext<typeof this>,\n  ): Promise<LangChainChatLLMOutput> {\n    const lcMessages = input.map((msg) => this.mappers.toLCMessage(msg));\n    const response = await this.lcLLM.invoke(lcMessages, {\n      ...options?.lc,\n      signal: run.signal,\n    });\n\n    return new LangChainChatLLMOutput(\n      [this.mappers.fromLCMessage(response)],\n      response.response_metadata,\n    );\n  }\n\n  protected async *_stream(\n    input: BaseMessage[],\n    options: MergedCallOptions<CallOptions>,\n    run: GetRunContext<typeof this>,\n  ): AsyncStream<LangChainChatLLMOutput> {\n    const lcMessages = input.map((msg) => this.mappers.toLCMessage(msg));\n    const response = this.lcLLM._streamResponseChunks(lcMessages, {\n      ...options?.lc,\n      signal: run.signal,\n    });\n    for await (const chunk of response) {\n      yield new LangChainChatLLMOutput(\n        [this.mappers.fromLCMessage(chunk.message)],\n        chunk.message.response_metadata,\n      );\n    }\n  }\n\n  createSnapshot() {\n    return {\n      ...super.createSnapshot(),\n      modelId: this.modelId,\n      modelMeta: this.modelMeta,\n      parameters: shallowCopy(this.parameters),\n      executionOptions: shallowCopy(this.executionOptions),\n      lcLLM: JSON.stringify(this.lcLLM.toJSON()),\n    };\n  }\n\n  async loadSnapshot({ lcLLM, ...state }: ReturnType<typeof this.createSnapshot>) {\n    super.loadSnapshot(state);\n    Object.assign(this, state, {\n      lcLLM: await (async () => {\n        if (lcLLM.includes(\"@ibm-generative-ai/node-sdk\")) {\n          const { GenAIChatModel } = await import(\"@ibm-generative-ai/node-sdk/langchain\");\n          return GenAIChatModel.fromJSON(lcLLM);\n        }\n\n        return await load(lcLLM);\n      })(),\n    });\n  }\n}\n"]}