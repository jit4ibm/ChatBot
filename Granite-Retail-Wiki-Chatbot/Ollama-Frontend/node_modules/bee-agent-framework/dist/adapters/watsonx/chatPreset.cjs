'use strict';

var llmChatTemplates_cjs = require('../shared/llmChatTemplates.cjs');

var __defProp = Object.defineProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
const WatsonXChatLLMPreset = {
  "meta-llama/llama-3-3-70b-instruct": /* @__PURE__ */ __name(() => {
    const { template, messagesToPrompt, parameters } = llmChatTemplates_cjs.LLMChatTemplates.get("llama3.3");
    return {
      base: {
        parameters: {
          decoding_method: "greedy",
          include_stop_sequence: false,
          max_new_tokens: 2048,
          repetition_penalty: 1,
          stop_sequences: [
            ...parameters.stop_sequence
          ]
        }
      },
      chat: {
        messagesToPrompt: messagesToPrompt(template)
      }
    };
  }, "meta-llama/llama-3-3-70b-instruct"),
  "ibm/granite-3-8b-instruct": /* @__PURE__ */ __name(() => {
    const { template, parameters, messagesToPrompt } = llmChatTemplates_cjs.LLMChatTemplates.get("granite3.1-Instruct");
    return {
      base: {
        parameters: {
          decoding_method: "greedy",
          max_new_tokens: 2048,
          include_stop_sequence: false,
          stop_sequences: [
            ...parameters.stop_sequence
          ]
        }
      },
      chat: {
        messagesToPrompt: messagesToPrompt(template)
      }
    };
  }, "ibm/granite-3-8b-instruct"),
  "ibm/granite-3-2b-instruct"() {
    return WatsonXChatLLMPreset["ibm/granite-3-8b-instruct"]();
  },
  "meta-llama/llama-3-1-70b-instruct": /* @__PURE__ */ __name(() => {
    const { template, messagesToPrompt, parameters } = llmChatTemplates_cjs.LLMChatTemplates.get("llama3.1");
    return {
      base: {
        parameters: {
          decoding_method: "greedy",
          include_stop_sequence: false,
          max_new_tokens: 2048,
          repetition_penalty: 1,
          stop_sequences: [
            ...parameters.stop_sequence
          ]
        }
      },
      chat: {
        messagesToPrompt: messagesToPrompt(template)
      }
    };
  }, "meta-llama/llama-3-1-70b-instruct"),
  "meta-llama/llama-3-1-405b-instruct"() {
    return WatsonXChatLLMPreset["meta-llama/llama-3-1-70b-instruct"]();
  },
  "meta-llama/llama-3-1-8b-instruct"() {
    return WatsonXChatLLMPreset["meta-llama/llama-3-1-70b-instruct"]();
  },
  "meta-llama/llama-3-70b-instruct": /* @__PURE__ */ __name(() => {
    const { template, messagesToPrompt, parameters } = llmChatTemplates_cjs.LLMChatTemplates.get("llama3");
    return {
      base: {
        parameters: {
          decoding_method: "greedy",
          max_new_tokens: 1500,
          include_stop_sequence: false,
          stop_sequences: [
            ...parameters.stop_sequence
          ]
        }
      },
      chat: {
        messagesToPrompt: messagesToPrompt(template)
      }
    };
  }, "meta-llama/llama-3-70b-instruct"),
  "meta-llama/llama-3-8b-instruct"() {
    return WatsonXChatLLMPreset["meta-llama/llama-3-70b-instruct"]();
  }
};

exports.WatsonXChatLLMPreset = WatsonXChatLLMPreset;
//# sourceMappingURL=chatPreset.cjs.map
//# sourceMappingURL=chatPreset.cjs.map