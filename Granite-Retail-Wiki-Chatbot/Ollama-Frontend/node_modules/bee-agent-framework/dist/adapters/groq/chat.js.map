{"version":3,"sources":["../../../src/adapters/groq/chat.ts"],"names":["ChatGroqOutput","ChatLLMOutput","responses","constructor","response","register","messages","flatMap","choices","choice","BaseMessage","of","role","delta","text","content","getTextContent","map","msg","join","merge","other","push","toString","createSnapshot","shallowCopy","loadSnapshot","snapshot","Object","assign","GroqChatLLM","ChatLLM","emitter","Emitter","root","child","namespace","creator","client","parameters","modelId","temperature","executionOptions","cache","Client","Serializer","toPlain","value","options","getPropStrict","fromPlain","meta","includes","tokenLimit","Infinity","embed","input","data","embeddings","create","model","msgs","encoding_format","signal","stream","embedding","tokenize","contentLength","reduce","acc","length","tokensCount","Math","ceil","_prepareRequest","message","guided","json","response_format","type","_generate","run","chat","completions","id","created","system_fingerprint","index","logprobs","finish_reason","_stream","chunk"],"mappings":";;;;;;;;;;AAwCO,MAAMA,uBAAuBC,aAAAA,CAAAA;EAxCpC;;;AAyCkBC,EAAAA,SAAAA;AAEhBC,EAAAA,WAAAA,CAAYC,QAAoB,EAAA;AAC9B,IAAK,KAAA,EAAA;AACL,IAAA,IAAA,CAAKF,SAAY,GAAA;AAACE,MAAAA;;AACpB;EAEA;AACE,IAAA,IAAA,CAAKC,QAAQ,EAAA;AACf;AAEA,EAAA,IAAIC,QAAW,GAAA;AACb,IAAA,OAAO,IAAKJ,CAAAA,SAAAA,CACTK,OAAQ,CAAA,CAACH,QAAaA,KAAAA,QAAAA,CAASI,OAAO,CAAA,CACtCD,OAAQ,CAAA,CAACE,MACRC,KAAAA,WAAAA,CAAYC,EAAG,CAAA;AACbC,MAAAA,IAAAA,EAAMH,OAAOI,KAAMD,CAAAA,IAAAA;AACnBE,MAAAA,IAAAA,EAAML,OAAOI,KAAME,CAAAA;AACrB,KAAA,CAAA,CAAA;AAEN;EAEAC,cAAyB,GAAA;AACvB,IAAO,OAAA,IAAA,CAAKV,SAASW,GAAI,CAAA,CAACC,QAAQA,GAAIJ,CAAAA,IAAI,CAAEK,CAAAA,IAAAA,CAAK,IAAA,CAAA;AACnD;AAEAC,EAAAA,KAAAA,CAAMC,KAA6B,EAAA;AACjC,IAAA,IAAA,CAAKnB,SAAUoB,CAAAA,IAAAA,CAAI,GAAID,KAAAA,CAAMnB,SAAS,CAAA;AACxC;EAEAqB,QAAmB,GAAA;AACjB,IAAA,OAAO,KAAKP,cAAc,EAAA;AAC5B;EAEAQ,cAAiB,GAAA;AACf,IAAO,OAAA;MACLtB,SAAWuB,EAAAA,WAAAA,CAAY,KAAKvB,SAAS;AACvC,KAAA;AACF;AAEAwB,EAAAA,YAAAA,CAAaC,QAAwD,EAAA;AACnEC,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMF,QAAAA,CAAAA;AACtB;AACF;AAYO,MAAMG,oBAAoBC,OAAAA,CAAAA;EAhGjC;;;EAiGkBC,OAAUC,GAAAA,OAAAA,CAAQC,KAAKC,KAAyB,CAAA;IAC9DC,SAAW,EAAA;AAAC,MAAA,MAAA;AAAQ,MAAA;;IACpBC,OAAS,EAAA;GACX,CAAA;AAEgBC,EAAAA,MAAAA;AACAC,EAAAA,UAAAA;AAEhBpC,EAAAA,WAAAA,CAAY,EACVmC,MAAAA,EACAE,OAAU,GAAA,yBAAA,EACVD,UAAa,GAAA;IACXE,WAAa,EAAA;AACf,GAAA,EACAC,mBAAmB,EAAC,EACpBC,KAAK,EAAA,GACI,EAAI,EAAA;AACb,IAAMH,KAAAA,CAAAA,OAAAA,EAASE,kBAAkBC,KAAAA,CAAAA;AACjC,IAAKL,IAAAA,CAAAA,MAAAA,GAASA,MAAU,IAAA,IAAIM,IAAAA,EAAAA;AAC5B,IAAKL,IAAAA,CAAAA,UAAAA,GAAaA,cAAc,EAAC;AACnC;EAEA;AACE,IAAA,IAAA,CAAKlC,QAAQ,EAAA;AACbwC,IAAAA,UAAAA,CAAWxC,SAASuC,IAAQ,EAAA;AAC1BE,MAAAA,OAAAA,0BAAUC,KAAW,MAAA;QACnBC,OAASC,EAAAA,aAAAA,CAAcF,OAAO,UAAA;OADvB,CAAA,EAAA,SAAA,CAAA;AAGTG,MAAAA,SAAAA,0BAAYH,KAAU,KAAA,IAAIH,IAAOG,CAAAA,KAAAA,CAAMC,OAAO,CAAnC,EAAA,WAAA;KACb,CAAA;AACF;AAEA,EAAA,MAAMG,IAAyB,GAAA;AAC7B,IAAA,IACE,IAAKX,CAAAA,OAAAA,CAAQY,QAAS,CAAA,OAAA,KACtB,IAAKZ,CAAAA,OAAAA,CAAQY,QAAS,CAAA,QAAA,CACtB,IAAA,IAAA,CAAKZ,OAAQY,CAAAA,QAAAA,CAAS,aAAA,CACtB,EAAA;AACA,MAAO,OAAA;AAAEC,QAAAA,UAAAA,EAAY,CAAI,GAAA;AAAK,OAAA;AAChC,KAAA,MAAA,IAAW,IAAKb,CAAAA,OAAAA,CAAQY,QAAS,CAAA,YAAA,CAAe,EAAA;AAC9C,MAAO,OAAA;AAAEC,QAAAA,UAAAA,EAAY,CAAI,GAAA;AAAK,OAAA;KACrB,MAAA,IAAA,IAAA,CAAKb,QAAQY,QAAS,CAAA,eAAA,KAAoB,IAAKZ,CAAAA,OAAAA,CAAQY,QAAS,CAAA,cAAA,CAAiB,EAAA;AAC1F,MAAO,OAAA;AAAEC,QAAAA,UAAAA,EAAY,GAAM,GAAA;AAAK,OAAA;AAClC,KAAA,MAAA,IAAW,IAAKb,CAAAA,OAAAA,CAAQY,QAAS,CAAA,cAAA,CAAiB,EAAA;AAChD,MAAO,OAAA;AAAEC,QAAAA,UAAAA,EAAY,EAAK,GAAA;AAAK,OAAA;AACjC;AAEA,IAAO,OAAA;MACLA,UAAYC,EAAAA;AACd,KAAA;AACF;EAEA,MAAMC,KAAAA,CAAMC,OAAwBR,OAAsD,EAAA;AACxF,IAAA,MAAM,EAAES,IAAI,EAAA,GAAK,MAAM,IAAKnB,CAAAA,MAAAA,CAAOoB,WAAWC,MAC5C,CAAA;AACEC,MAAAA,KAAAA,EAAO,IAAKpB,CAAAA,OAAAA;MACZgB,KAAOA,EAAAA,KAAAA,CAAMjD,OAAQ,CAAA,CAACsD,IAASA,KAAAA,IAAAA,CAAK5C,IAAI,CAACC,GAAAA,KAAQA,GAAIJ,CAAAA,IAAI,CAAA,CAAA;MACzDgD,eAAiB,EAAA;KAEnB,EAAA;AACEC,MAAAA,MAAAA,EAAQf,OAASe,EAAAA,MAAAA;MACjBC,MAAQ,EAAA;KACV,CAAA;AAEF,IAAO,OAAA;AAAEN,MAAAA,UAAAA,EAAYD,KAAKxC,GAAI,CAAA,CAAC,EAAEgD,SAAAA,OAAgBA,SAAAA;AAAuB,KAAA;AAC1E;AAEA,EAAA,MAAMC,SAASV,KAAsD,EAAA;AACnE,IAAMW,MAAAA,aAAAA,GAAgBX,KAAMY,CAAAA,MAAAA,CAAO,CAACC,GAAAA,EAAKnD,QAAQmD,GAAMnD,GAAAA,GAAAA,CAAIJ,IAAKwD,CAAAA,MAAAA,EAAQ,CAAA,CAAA;AAExE,IAAO,OAAA;MACLC,WAAaC,EAAAA,IAAAA,CAAKC,IAAKN,CAAAA,aAAAA,GAAgB,CAAA;AACzC,KAAA;AACF;AAEUO,EAAAA,eAAAA,CACRlB,OACAR,OAC4B,EAAA;AAC5B,IAAO,OAAA;AACL,MAAA,GAAG,IAAKT,CAAAA,UAAAA;AACRqB,MAAAA,KAAAA,EAAO,IAAKpB,CAAAA,OAAAA;MACZwB,MAAQ,EAAA,KAAA;MACR1D,QAAUkD,EAAAA,KAAAA,CAAMvC,GACd,CAAA,CAAC0D,OACE,MAAA;AACC/D,QAAAA,IAAAA,EAAM+D,OAAQ/D,CAAAA,IAAAA;AACdG,QAAAA,OAAAA,EAAS4D,OAAQ7D,CAAAA;OACnB,CAAA,CAAA;MAEJ,GAAIkC,OAAAA,EAAS4B,QAAQC,IAAQ,IAAA;QAC3BC,eAAiB,EAAA;UACfC,IAAM,EAAA;AACR;AACF;AACF,KAAA;AACF;EAEA,MAAgBC,SAAAA,CACdxB,KACAR,EAAAA,OAAAA,EACAiC,GACyB,EAAA;AACzB,IAAA,MAAM7E,WAAW,MAAM,IAAA,CAAKkC,MAAO4C,CAAAA,IAAAA,CAAKC,YAAYxB,MAClD,CAAA;MACE,GAAG,IAAA,CAAKe,eAAgBlB,CAAAA,KAAAA,EAAOR,OAAAA,CAAAA;MAC/BgB,MAAQ,EAAA;KAEV,EAAA;AACED,MAAAA,MAAAA,EAAQkB,GAAIlB,CAAAA;KACd,CAAA;AAEF,IAAA,OAAO,IAAI/D,cAAe,CAAA;AACxBoF,MAAAA,EAAAA,EAAIhF,QAASgF,CAAAA,EAAAA;AACbxB,MAAAA,KAAAA,EAAOxD,QAASwD,CAAAA,KAAAA;AAChByB,MAAAA,OAAAA,EAASjF,QAASiF,CAAAA,OAAAA;AAClBC,MAAAA,kBAAAA,EAAoBlF,QAASkF,CAAAA,kBAAAA;AAC7B9E,MAAAA,OAAAA,EAASJ,QAASI,CAAAA,OAAAA,CAAQS,GACxB,CAAA,CAACR,MACE,MAAA;AACCI,QAAAA,KAAAA,EAAOJ,MAAOkE,CAAAA,OAAAA;AACdY,QAAAA,KAAAA,EAAO9E,MAAO8E,CAAAA,KAAAA;AACdC,QAAAA,QAAAA,EAAU/E,MAAO+E,CAAAA,QAAAA;AACjBC,QAAAA,aAAAA,EAAehF,MAAOgF,CAAAA;OACxB,CAAA;KAEN,CAAA;AACF;EAEA,OAAiBC,OAAAA,CACflC,KACAR,EAAAA,OAAAA,EACAiC,GAC6B,EAAA;AAC7B,IAAA,WAAA,MAAiBU,SAAS,MAAM,IAAA,CAAKrD,MAAO4C,CAAAA,IAAAA,CAAKC,YAAYxB,MAC3D,CAAA;MACE,GAAG,IAAA,CAAKe,eAAgBlB,CAAAA,KAAAA,EAAOR,OAAAA,CAAAA;MAC/BgB,MAAQ,EAAA;KAEV,EAAA;AACED,MAAAA,MAAAA,EAAQkB,GAAIlB,CAAAA;AACd,KAAA,CACC,EAAA;AACD,MAAM,MAAA,IAAI/D,eAAe2F,KAAAA,CAAAA;AAC3B;AACF;EAEAnE,cAAiB,GAAA;AACf,IAAO,OAAA;AACL,MAAA,GAAG,MAAMA,cAAAA,EAAAA;MACTe,UAAYd,EAAAA,WAAAA,CAAY,KAAKc,UAAU,CAAA;AACvCD,MAAAA,MAAAA,EAAQ,IAAKA,CAAAA;AACf,KAAA;AACF;AACF","file":"chat.js","sourcesContent":["/**\n * Copyright 2024 IBM Corp.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AsyncStream,\n  BaseLLMTokenizeOutput,\n  EmbeddingOptions,\n  EmbeddingOutput,\n  ExecutionOptions,\n  GenerateOptions,\n  LLMCache,\n  LLMMeta,\n  StreamGenerateOptions,\n} from \"@/llms/base.js\";\nimport { shallowCopy } from \"@/serializer/utils.js\";\nimport { ChatLLM, ChatLLMGenerateEvents, ChatLLMOutput } from \"@/llms/chat.js\";\nimport { BaseMessage, RoleType } from \"@/llms/primitives/message.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport { ClientOptions, Groq as Client } from \"groq-sdk\";\nimport { GetRunContext } from \"@/context.js\";\nimport { Serializer } from \"@/serializer/serializer.js\";\nimport { getPropStrict } from \"@/internals/helpers/object.js\";\nimport { ChatCompletionCreateParams } from \"groq-sdk/resources/chat/completions\";\n\ntype Parameters = Omit<ChatCompletionCreateParams, \"stream\" | \"messages\" | \"model\">;\ntype Response = Omit<Client.Chat.ChatCompletionChunk, \"object\">;\n\nexport class ChatGroqOutput extends ChatLLMOutput {\n  public readonly responses: Response[];\n\n  constructor(response: Response) {\n    super();\n    this.responses = [response];\n  }\n\n  static {\n    this.register();\n  }\n\n  get messages() {\n    return this.responses\n      .flatMap((response) => response.choices)\n      .flatMap((choice) =>\n        BaseMessage.of({\n          role: choice.delta.role as RoleType,\n          text: choice.delta.content!,\n        }),\n      );\n  }\n\n  getTextContent(): string {\n    return this.messages.map((msg) => msg.text).join(\"\\n\");\n  }\n\n  merge(other: ChatGroqOutput): void {\n    this.responses.push(...other.responses);\n  }\n\n  toString(): string {\n    return this.getTextContent();\n  }\n\n  createSnapshot() {\n    return {\n      responses: shallowCopy(this.responses),\n    };\n  }\n\n  loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void {\n    Object.assign(this, snapshot);\n  }\n}\n\ninterface Input {\n  modelId?: string;\n  client?: Client;\n  parameters?: Parameters;\n  executionOptions?: ExecutionOptions;\n  cache?: LLMCache<ChatGroqOutput>;\n}\n\nexport type GroqChatLLMEvents = ChatLLMGenerateEvents<ChatGroqOutput>;\n\nexport class GroqChatLLM extends ChatLLM<ChatGroqOutput> {\n  public readonly emitter = Emitter.root.child<GroqChatLLMEvents>({\n    namespace: [\"groq\", \"chat_llm\"],\n    creator: this,\n  });\n\n  public readonly client: Client;\n  public readonly parameters: Partial<Parameters>;\n\n  constructor({\n    client,\n    modelId = \"llama-3.1-70b-versatile\",\n    parameters = {\n      temperature: 0,\n    },\n    executionOptions = {},\n    cache,\n  }: Input = {}) {\n    super(modelId, executionOptions, cache);\n    this.client = client ?? new Client();\n    this.parameters = parameters ?? {};\n  }\n\n  static {\n    this.register();\n    Serializer.register(Client, {\n      toPlain: (value) => ({\n        options: getPropStrict(value, \"_options\") as ClientOptions,\n      }),\n      fromPlain: (value) => new Client(value.options),\n    });\n  }\n\n  async meta(): Promise<LLMMeta> {\n    if (\n      this.modelId.includes(\"gemma\") ||\n      this.modelId.includes(\"llama3\") ||\n      this.modelId.includes(\"llama-guard\")\n    ) {\n      return { tokenLimit: 8 * 1024 };\n    } else if (this.modelId.includes(\"llava-v1.5\")) {\n      return { tokenLimit: 4 * 1024 };\n    } else if (this.modelId.includes(\"llama-3.1-70b\") || this.modelId.includes(\"llama-3.1-8b\")) {\n      return { tokenLimit: 128 * 1024 };\n    } else if (this.modelId.includes(\"mixtral-8x7b\")) {\n      return { tokenLimit: 32 * 1024 };\n    }\n\n    return {\n      tokenLimit: Infinity,\n    };\n  }\n\n  async embed(input: BaseMessage[][], options?: EmbeddingOptions): Promise<EmbeddingOutput> {\n    const { data } = await this.client.embeddings.create(\n      {\n        model: this.modelId,\n        input: input.flatMap((msgs) => msgs.map((msg) => msg.text)) as string[],\n        encoding_format: \"float\",\n      },\n      {\n        signal: options?.signal,\n        stream: false,\n      },\n    );\n    return { embeddings: data.map(({ embedding }) => embedding as number[]) };\n  }\n\n  async tokenize(input: BaseMessage[]): Promise<BaseLLMTokenizeOutput> {\n    const contentLength = input.reduce((acc, msg) => acc + msg.text.length, 0);\n\n    return {\n      tokensCount: Math.ceil(contentLength / 4),\n    };\n  }\n\n  protected _prepareRequest(\n    input: BaseMessage[],\n    options: GenerateOptions,\n  ): ChatCompletionCreateParams {\n    return {\n      ...this.parameters,\n      model: this.modelId,\n      stream: false,\n      messages: input.map(\n        (message) =>\n          ({\n            role: message.role,\n            content: message.text,\n          }) as Client.Chat.ChatCompletionMessageParam,\n      ),\n      ...(options?.guided?.json && {\n        response_format: {\n          type: \"json_object\",\n        },\n      }),\n    };\n  }\n\n  protected async _generate(\n    input: BaseMessage[],\n    options: GenerateOptions,\n    run: GetRunContext<typeof this>,\n  ): Promise<ChatGroqOutput> {\n    const response = await this.client.chat.completions.create(\n      {\n        ...this._prepareRequest(input, options),\n        stream: false,\n      },\n      {\n        signal: run.signal,\n      },\n    );\n    return new ChatGroqOutput({\n      id: response.id,\n      model: response.model,\n      created: response.created,\n      system_fingerprint: response.system_fingerprint,\n      choices: response.choices.map(\n        (choice) =>\n          ({\n            delta: choice.message,\n            index: choice.index,\n            logprobs: choice.logprobs,\n            finish_reason: choice.finish_reason,\n          }) as Client.Chat.ChatCompletionChunk.Choice,\n      ),\n    });\n  }\n\n  protected async *_stream(\n    input: BaseMessage[],\n    options: Partial<StreamGenerateOptions>,\n    run: GetRunContext<typeof this>,\n  ): AsyncStream<ChatGroqOutput> {\n    for await (const chunk of await this.client.chat.completions.create(\n      {\n        ...this._prepareRequest(input, options),\n        stream: true,\n      },\n      {\n        signal: run.signal,\n      },\n    )) {\n      yield new ChatGroqOutput(chunk);\n    }\n  }\n\n  createSnapshot() {\n    return {\n      ...super.createSnapshot(),\n      parameters: shallowCopy(this.parameters),\n      client: this.client,\n    };\n  }\n}\n"]}